services:
  breakitdown:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: breakitdown
    ports:
      - "3000:3000"
    environment:
      # OpenAI Configuration (optional if using Ollama)
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o}
      
      # Ollama Configuration (connecting to existing Ollama instance at ollama:11434)
      - USE_OLLAMA=${USE_OLLAMA:-true}
      - OLLAMA_URL=${OLLAMA_URL:-http://ollama:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-gpt-oss:20b}
      
      # Local Speech Services (STT & TTS)
      - USE_LOCAL_WHISPER=${USE_LOCAL_WHISPER:-false}
      - WHISPER_URL=${WHISPER_URL:-http://whisper:9000}
      - TTS_URL=${TTS_URL:-http://tts:9001}
      
      # Node environment
      - NODE_ENV=production
      - NITRO_PORT=3000
      - NITRO_HOST=0.0.0.0
    restart: unless-stopped
    networks:
      - proxy  # Connect to Ollama's network (same network used by Cloudtastic services)

networks:
  # Connect to the existing 'proxy' network used by Ollama and other Cloudtastic services
  proxy:
    external: true
